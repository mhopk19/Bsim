{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bce51fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Step: 0, Loss: 0.03965402767062187\n",
      "epoch 1\n",
      "Step: 1, Loss: 0.02076491340994835\n",
      "epoch 2\n",
      "Step: 2, Loss: 0.014110084623098373\n",
      "epoch 3\n",
      "Step: 3, Loss: 0.002376302843913436\n",
      "epoch 4\n",
      "Step: 4, Loss: 0.0019026579102501273\n",
      "epoch 5\n",
      "Step: 5, Loss: 0.000939610879868269\n",
      "epoch 6\n",
      "Step: 6, Loss: 0.0007219105609692633\n",
      "epoch 7\n",
      "Step: 7, Loss: 0.0003942791372537613\n",
      "epoch 8\n",
      "Step: 8, Loss: 0.00032781570916995406\n",
      "epoch 9\n",
      "Step: 9, Loss: 0.00022571887529920787\n",
      "epoch 10\n",
      "Step: 10, Loss: 0.000144373785587959\n",
      "epoch 11\n",
      "Step: 11, Loss: 7.323654426727444e-05\n",
      "epoch 12\n",
      "Step: 12, Loss: 4.331710806582123e-05\n",
      "epoch 13\n",
      "Step: 13, Loss: 2.7907379262614995e-05\n",
      "epoch 14\n",
      "Step: 14, Loss: 2.0822017177124508e-05\n",
      "epoch 15\n",
      "Step: 15, Loss: 1.945869553310331e-05\n",
      "epoch 16\n",
      "Step: 16, Loss: 1.8340404494665563e-05\n",
      "epoch 17\n",
      "Step: 17, Loss: 1.5309387890738435e-05\n",
      "epoch 18\n",
      "Step: 18, Loss: 1.4679071682621725e-05\n",
      "epoch 19\n",
      "Step: 19, Loss: 1.4097829989623278e-05\n",
      "epoch 20\n",
      "Step: 20, Loss: 1.2855682143708691e-05\n",
      "epoch 21\n",
      "Step: 21, Loss: 1.2207604413561057e-05\n",
      "epoch 22\n",
      "Step: 22, Loss: 1.1835001714644022e-05\n",
      "epoch 23\n",
      "Step: 23, Loss: 1.1605730833252892e-05\n",
      "epoch 24\n",
      "Step: 24, Loss: 1.1271049515926279e-05\n",
      "epoch 25\n",
      "Step: 25, Loss: 1.0986820598191116e-05\n",
      "epoch 26\n",
      "Step: 26, Loss: 1.0751706213341095e-05\n",
      "epoch 27\n",
      "Step: 27, Loss: 1.0557086170592811e-05\n",
      "epoch 28\n",
      "Step: 28, Loss: 1.015912857837975e-05\n",
      "epoch 29\n",
      "Step: 29, Loss: 9.782064807950519e-06\n",
      "epoch 30\n",
      "Step: 30, Loss: 9.608212167222518e-06\n",
      "epoch 31\n",
      "Step: 31, Loss: 9.513031727692578e-06\n",
      "epoch 32\n",
      "Step: 32, Loss: 9.243202839570586e-06\n",
      "epoch 33\n",
      "Step: 33, Loss: 8.200702723115683e-06\n",
      "epoch 34\n",
      "Step: 34, Loss: 7.994131919986103e-06\n",
      "epoch 35\n",
      "Step: 35, Loss: 7.952602572913747e-06\n",
      "epoch 36\n",
      "Step: 36, Loss: 7.857489435991738e-06\n",
      "epoch 37\n",
      "Step: 37, Loss: 7.364962129940977e-06\n",
      "epoch 38\n",
      "Step: 38, Loss: 6.964816748222802e-06\n",
      "epoch 39\n",
      "Step: 39, Loss: 6.842454695288325e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 50 # number of samples\n",
    "L = 300 # length of each sample (number of values for each sine wave)\n",
    "T = 20 # width of the wave\n",
    "\n",
    "x = np.empty((N,L), np.float32) # instantiate empty array\n",
    "random_shift = np.random.randint(-4*T, 4*T, N).reshape(N,1)\n",
    "x[:] = np.arange(L) + random_shift\n",
    "y = np.sin(x/1.0/T).astype(np.float32)\n",
    "\n",
    "\n",
    "# every row of x is a list of positions x in the sin function, where each row is shifted by an amount\n",
    "# y is the output of the sin function, sin(x) at every point x\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_layers=64):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        # lstm1, lstm2, linear are all layers in the network\n",
    "        self.lstm1 = nn.LSTMCell(1, self.hidden_layers)\n",
    "        self.lstm2 = nn.LSTMCell(self.hidden_layers, self.hidden_layers)\n",
    "        self.linear = nn.Linear(self.hidden_layers, 1)\n",
    "        \n",
    "    def forward(self, y, future_preds=0):\n",
    "        outputs, num_samples = [], y.size(0)\n",
    "        h_t = torch.zeros(num_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        c_t = torch.zeros(num_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        h_t2 = torch.zeros(num_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        c_t2 = torch.zeros(num_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        \n",
    "        for time_step in y.split(1, dim=1):\n",
    "            # N, 1\n",
    "            h_t, c_t = self.lstm1(time_step, (h_t, c_t)) # initial hidden and cell states\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2)) # new hidden and cell states\n",
    "            output = self.linear(h_t2) # output from the last FC layer\n",
    "            outputs.append(output)\n",
    "            \n",
    "        for i in range(future_preds):\n",
    "            # this only generates future predictions if we pass in future_preds>0\n",
    "            # mirrors the code above, using last output/prediction as input\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs.append(output)\n",
    "            \n",
    "        # transform list to tensor    \n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "train_input = torch.from_numpy(y[3:, :-1]) # (97, 999)\n",
    "train_target = torch.from_numpy(y[3:, 1:]) # (97, 999)\n",
    "\n",
    "test_input = torch.from_numpy(y[:3, :-1]) # (3, 999)\n",
    "test_target = torch.from_numpy(y[:3, 1:]) # (3, 999)\n",
    "\n",
    "model = LSTM()\n",
    "criterion = nn.MSELoss()\n",
    "optimiser = optim.LBFGS(model.parameters(), lr=0.08)\n",
    "\n",
    "def training_loop(n_epochs, model, optimiser, loss_fn, \n",
    "                  train_input, train_target, test_input, test_target):\n",
    "    for i in range(n_epochs):\n",
    "        print(\"epoch\", i)\n",
    "        def closure():\n",
    "            optimiser.zero_grad()\n",
    "            out = model(train_input)\n",
    "            loss = loss_fn(out, train_target)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        optimiser.step(closure)\n",
    "        with torch.no_grad():\n",
    "            future = L\n",
    "            pred = model(test_input, future_preds=future)\n",
    "            # use all pred samples, but only go to 999\n",
    "            loss = loss_fn(pred[:, :-future], test_target)\n",
    "            y = pred.detach().numpy()\n",
    "        # draw figures\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.title(f\"Step {i+1}\")\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        plt.xticks(fontsize=20)\n",
    "        plt.yticks(fontsize=20)\n",
    "        n = train_input.shape[1] # 999\n",
    "        def draw(yi, colour):\n",
    "            plt.plot(np.arange(n), yi[:n], colour, linewidth=2.0)\n",
    "            plt.plot(np.arange(n, n+future), yi[n:], colour+\":\", linewidth=2.0)\n",
    "        draw(y[0], 'r')\n",
    "        draw(y[1], 'b')\n",
    "        draw(y[2], 'g')\n",
    "        plt.savefig(\"predict%d.png\"%i, dpi=200)\n",
    "        plt.close()\n",
    "        # print the loss\n",
    "        out = model(train_input)\n",
    "        loss_print = loss_fn(out, train_target)\n",
    "        print(\"Step: {}, Loss: {}\".format(i, loss_print))\n",
    "\n",
    "training_loop(40, model, optimiser, criterion, train_input, train_target, test_input, test_target)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf07487d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd680da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
